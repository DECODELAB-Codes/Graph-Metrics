{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bf631c-2000-43e5-a544-8e6c8c79449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PageRank Analysis for Neuronal Directed Graphs\n",
    "# Based on Mean Edge Weights (assumed positive)\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import ast\n",
    "\n",
    "# ==== USER INPUT: Specify file paths here ====\n",
    "edge_weights_path = r\"/your/path/to/segment_edge_weights.xlsx\"  # <-- CHANGE THIS\n",
    "output_path = r\"/your/path/to/pagerank_segment.xlsx\"            # <-- CHANGE THIS\n",
    "\n",
    "# ==== FUNCTION DEFINITION ====\n",
    "def compute_pagerank(edge_weights_path, output_path='pagerank.xlsx'):\n",
    "    \"\"\"\n",
    "    Compute PageRank for a directed neuronal network based on positive mean edge weights.\n",
    "\n",
    "    This function builds a directed graph where each node is a neuron and each edge \n",
    "    represents a directed connection with a weight corresponding to the mean functional connectivity \n",
    "    (e.g., derived from dot products of firing rates). PageRank is computed to quantify the \n",
    "    influence of each neuron, under the assumption that connections from high-scoring neurons \n",
    "    contribute more to the score than those from low-scoring ones.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    edge_weights_path : str\n",
    "        Path to Excel file containing 'Neuron Pair' and 'Mean Edge Weight' columns.\n",
    "        'Neuron Pair' must be string-formatted tuples, e.g., \"(1, 2)\".\n",
    "\n",
    "    output_path : str, optional\n",
    "        File path to save the resulting PageRank table. Default is 'pagerank.xlsx'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pagerank_df : pandas.DataFrame\n",
    "        DataFrame containing each neuron and its corresponding PageRank score.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function assumes the input file contains data from a single animal. \n",
    "    All neuron pairs are treated as part of a single directed graph, and PageRank \n",
    "    is computed across that network. If you have data from multiple animals in one file, \n",
    "    you must preprocess the file to split by animal and call this function separately \n",
    "    for each subset.\n",
    "    \"\"\"\n",
    "    # Load edge weight data\n",
    "    edge_weights_df = pd.read_excel(edge_weights_path)\n",
    "\n",
    "    # Convert string-formatted neuron pairs to tuples safely\n",
    "    edge_weights_df['Neuron Pair'] = edge_weights_df['Neuron Pair'].apply(ast.literal_eval)\n",
    "\n",
    "    # Build directed graph and add weighted edges\n",
    "    G = nx.DiGraph()\n",
    "    for _, row in edge_weights_df.iterrows():\n",
    "        source, target = row['Neuron Pair']\n",
    "        weight = row['Mean Edge Weight']\n",
    "        G.add_edge(source, target, weight=weight)\n",
    "\n",
    "    # Compute PageRank using weighted edges\n",
    "    pagerank_scores = nx.pagerank(G, weight='weight')\n",
    "\n",
    "    # Convert to DataFrame and save\n",
    "    pagerank_df = pd.DataFrame(pagerank_scores.items(), columns=['Neuron', 'PageRank'])\n",
    "    pagerank_df.to_excel(output_path, index=False)\n",
    "\n",
    "    return pagerank_df\n",
    "\n",
    "# ==== RUN THE FUNCTION AND PRINT OUTPUT ====\n",
    "pagerank_df = compute_pagerank(edge_weights_path, output_path)\n",
    "print(pagerank_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478d03f0-6fbf-4e1d-b07d-328787a2fe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted Clustering Coefficient per Neuron per Animal\n",
    "# Measures how strongly each neuron's neighbors are interconnected using edge weights.\n",
    "# Computed on an undirected graph using NetworkX.\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import ast\n",
    "\n",
    "# === USER INPUT ===\n",
    "edge_weights_path = r\"/your/path/to/mean_edge_weights_all_animals.xlsx\"  # <-- CHANGE THIS\n",
    "output_path = r\"/your/path/to/weighted_clustering_all_animals.xlsx\"      # <-- CHANGE THIS\n",
    "\n",
    "# === FUNCTION DEFINITION ===\n",
    "def compute_weighted_clustering(edge_weights_path, output_path='weighted_clustering.xlsx'):\n",
    "    \"\"\"\n",
    "    Compute the weighted clustering coefficient for each neuron across animals.\n",
    "\n",
    "    Builds an undirected graph per animal from functional connectivity data and computes\n",
    "    the weighted clustering coefficient, which quantifies how strongly a neuron's neighbors \n",
    "    are interconnected, accounting for edge weights. By calculating the weighted clustering coefficient for each neuron, \n",
    "    we can identify which neurons form tightly connected clusters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    edge_weights_path : str\n",
    "        Path to Excel file containing columns:\n",
    "        - 'Animal': Animal identifier\n",
    "        - 'Neuron Pair': Tuple of neurons as a string (e.g., \"(1, 2)\")\n",
    "        - 'Mean Edge Weight': Positive float weight between neurons\n",
    "\n",
    "    output_path : str, optional\n",
    "        Path to save the combined clustering results. Default is 'weighted_clustering.xlsx'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    final_results_df : pandas.DataFrame\n",
    "        DataFrame with columns: Neuron, Weighted Clustering Coefficient, Animal\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function handles multiple animals within a single input sheet by grouping \n",
    "    based on the 'Animal' column. If you are processing one animal at a time, use a \n",
    "    version of this function that skips the groupby step.\n",
    "    \"\"\"\n",
    "    # Load edge weight data\n",
    "    df = pd.read_excel(edge_weights_path)\n",
    "\n",
    "    # Safely parse neuron pairs\n",
    "    df['Neuron Pair'] = df['Neuron Pair'].apply(ast.literal_eval)\n",
    "\n",
    "    # Store results\n",
    "    all_results = []\n",
    "\n",
    "    # Group by animal and compute clustering coefficient for each\n",
    "    for animal, group in df.groupby('Animal'):\n",
    "        G = nx.Graph()\n",
    "        for _, row in group.iterrows():\n",
    "            source, target = row['Neuron Pair']\n",
    "            weight = row['Mean Edge Weight']\n",
    "            G.add_edge(source, target, weight=weight)\n",
    "\n",
    "        clustering = nx.clustering(G, weight='weight')\n",
    "        clustering_df = pd.DataFrame(clustering.items(), columns=['Neuron', 'Weighted Clustering Coefficient'])\n",
    "        clustering_df['Animal'] = animal\n",
    "        all_results.append(clustering_df)\n",
    "\n",
    "    final_results_df = pd.concat(all_results, ignore_index=True)\n",
    "    final_results_df.to_excel(output_path, index=False)\n",
    "\n",
    "    return final_results_df\n",
    "\n",
    "# === RUN THE FUNCTION AND PRINT OUTPUT ===\n",
    "clustering_df = compute_weighted_clustering(edge_weights_path, output_path)\n",
    "print(clustering_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff2fd4c-ef5f-498e-9f97-42d0587ec46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted Degree Centrality (Raw and Normalized)\n",
    "# Measures total edge weight per neuron in an undirected graph, per animal\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import ast\n",
    "\n",
    "# === USER INPUT ===\n",
    "edge_weights_path = r\"/your/path/to/mean_edge_weights_all_animals.xlsx\"  # <-- CHANGE THIS\n",
    "output_path = r\"/your/path/to/weighted_degree_centrality_all_animals.xlsx\"  # <-- CHANGE THIS\n",
    "\n",
    "# === FUNCTION DEFINITION ===\n",
    "def compute_weighted_degree_centrality(edge_weights_path, output_path='weighted_degree_centrality.xlsx'):\n",
    "    \"\"\"\n",
    "    Compute raw and normalized weighted degree centrality for each neuron, grouped per animal.\n",
    "\n",
    "    This function assumes the input file contains data for multiple animals, with an 'Animal' column\n",
    "    that identifies which edges belong to which animal. A separate undirected graph is constructed\n",
    "    for each animal based on its neuron pairs and edge weights. Weighted degree centrality is computed \n",
    "    as the sum of edge weights per neuron. The normalized value is calculated by dividing each neuron's \n",
    "    weighted degree by the total number of neurons in that animal's network.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    edge_weights_path : str\n",
    "        Path to Excel file containing:\n",
    "        - 'Animal': Animal identifier (e.g., \"WT1\", \"ELS2\")\n",
    "        - 'Neuron Pair': Tuple as string (e.g., \"(1, 2)\")\n",
    "        - 'Mean Edge Weight': Positive float\n",
    "\n",
    "    output_path : str, optional\n",
    "        File path to save output Excel file. Default is 'weighted_degree_centrality.xlsx'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    final_results_df : pandas.DataFrame\n",
    "        DataFrame with columns:\n",
    "        - 'Neuron'\n",
    "        - 'Weighted Degree'\n",
    "        - 'Normalized Weighted Degree'\n",
    "        - 'Animal'\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function handles multiple animals within a single input sheet by grouping \n",
    "    based on the 'Animal' column. If you are processing one animal at a time, use a \n",
    "    version of this function that skips the groupby step.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_excel(edge_weights_path)\n",
    "    df['Neuron Pair'] = df['Neuron Pair'].apply(ast.literal_eval)\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    for animal, group in df.groupby('Animal'):\n",
    "        G = nx.Graph()\n",
    "        for _, row in group.iterrows():\n",
    "            source, target = row['Neuron Pair']\n",
    "            weight = row['Mean Edge Weight']\n",
    "            G.add_edge(source, target, weight=weight)\n",
    "\n",
    "        # Compute raw weighted degree (sum of edge weights per node)\n",
    "        weighted_degrees = {\n",
    "            node: sum(attr['weight'] for _, attr in G[node].items())\n",
    "            for node in G.nodes()\n",
    "        }\n",
    "\n",
    "        num_neurons = len(G.nodes())\n",
    "        normalized_degrees = {\n",
    "            node: degree / num_neurons\n",
    "            for node, degree in weighted_degrees.items()\n",
    "        }\n",
    "\n",
    "        degrees_df = pd.DataFrame({\n",
    "            'Neuron': list(weighted_degrees.keys()),\n",
    "            'Weighted Degree': list(weighted_degrees.values()),\n",
    "            'Normalized Weighted Degree': list(normalized_degrees.values())\n",
    "        })\n",
    "        degrees_df['Animal'] = animal\n",
    "        all_results.append(degrees_df)\n",
    "\n",
    "    final_results_df = pd.concat(all_results, ignore_index=True)\n",
    "    final_results_df.to_excel(output_path, index=False)\n",
    "\n",
    "    return final_results_df\n",
    "\n",
    "# === RUN FUNCTION ===\n",
    "degree_df = compute_weighted_degree_centrality(edge_weights_path, output_path)\n",
    "print(degree_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d98f2a-23cb-4a5f-b5f5-911ff1ee88b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HITS Algorithm for Directed Graphs in a Neural Network\n",
    "# Identifies hub and authority neurons based on connectivity structure\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import ast\n",
    "\n",
    "# === USER INPUT ===\n",
    "edge_weights_path = r\"/your/path/to/mean_edge_weights_single_animal.xlsx\"   # <-- CHANGE THIS\n",
    "hub_output_path = r\"/your/path/to/hub_scores.xlsx\"                          # <-- CHANGE THIS\n",
    "auth_output_path = r\"/your/path/to/authority_scores.xlsx\"                   # <-- CHANGE THIS\n",
    "\n",
    "# === FUNCTION DEFINITION ===\n",
    "def compute_hits_scores(edge_weights_path, hub_output_path='hub_scores.xlsx', auth_output_path='authority_scores.xlsx'):\n",
    "    \"\"\"\n",
    "    Compute HITS (Hyperlink-Induced Topic Search) scores for neurons in a directed graph.\n",
    "\n",
    "    HITS identifies two types of central nodes:\n",
    "    - Hubs: Neurons that connect to many high-authority neurons\n",
    "    - Authorities: Neurons that are linked to by many good hubs\n",
    "\n",
    "    The algorithm assumes a directed graph of positive-weighted connections between neurons.\n",
    "    Note: The standard NetworkX implementation of HITS does not use edge weights — only the\n",
    "    directionality of connections is considered.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    edge_weights_path : str\n",
    "        Path to Excel file containing:\n",
    "        - 'Neuron Pair': stringified tuple (e.g., \"(1, 2)\")\n",
    "        - 'Mean Edge Weight': positive float (used only to define edges)\n",
    "\n",
    "    hub_output_path : str, optional\n",
    "        Path to save hub scores. Default is 'hub_scores.xlsx'.\n",
    "\n",
    "    auth_output_path : str, optional\n",
    "        Path to save authority scores. Default is 'authority_scores.xlsx'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    hubs_df : pandas.DataFrame\n",
    "        DataFrame with neurons and their Hub scores.\n",
    "\n",
    "    authorities_df : pandas.DataFrame\n",
    "        DataFrame with neurons and their Authority scores.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function assumes the input file contains data from a single animal. \n",
    "    All neuron pairs are treated as part of a single directed graph. If you have multiple\n",
    "    animals in one file, you must split the data and call this function separately per animal.\n",
    "\n",
    "    Edge weights are used to define edge presence but are not considered in the HITS calculation. \n",
    "    NetworkX’s HITS implementation operates on the binary structure of the directed graph.\n",
    "\n",
    "    Although the code does not show iterations explicitly, HITS is an iterative algorithm. \n",
    "    NetworkX handles this process internally using the following approach:\n",
    "\n",
    "    - Initializes all hub and authority scores to 1\n",
    "    - Repeatedly updates scores until convergence:\n",
    "        * Each neuron's authority score becomes the sum of the hub scores of neurons pointing to it\n",
    "        * Each neuron's hub score becomes the sum of the authority scores of neurons it points to\n",
    "    - Scores are normalized after each iteration\n",
    "    - The algorithm stops when the change in scores falls below a tolerance threshold or \n",
    "      after a maximum number of iterations (default: max_iter=100, tol=1e-8)\n",
    "\n",
    "    To manually control convergence behavior, you can pass parameters such as `max_iter` and `tol` \n",
    "    to `nx.hits()`.\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(edge_weights_path)\n",
    "    df['Neuron Pair'] = df['Neuron Pair'].apply(ast.literal_eval)\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "    for _, row in df.iterrows():\n",
    "        source, target = row['Neuron Pair']\n",
    "        G.add_edge(source, target)  # weights ignored by nx.hits()\n",
    "\n",
    "    hubs, authorities = nx.hits(G)\n",
    "\n",
    "    hubs_df = pd.DataFrame(hubs.items(), columns=['Neuron', 'Hub Score'])\n",
    "    authorities_df = pd.DataFrame(authorities.items(), columns=['Neuron', 'Authority Score'])\n",
    "\n",
    "    hubs_df.to_excel(hub_output_path, index=False)\n",
    "    authorities_df.to_excel(auth_output_path, index=False)\n",
    "\n",
    "    return hubs_df, authorities_df\n",
    "\n",
    "# === RUN FUNCTION ===\n",
    "hubs_df, authorities_df = compute_hits_scores(edge_weights_path, hub_output_path, auth_output_path)\n",
    "\n",
    "print(\"Hub Scores:\\n\", hubs_df)\n",
    "print(\"\\nAuthority Scores:\\n\", authorities_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4369cc37-3393-48c0-a136-cd3edef084dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leiden Community Detection for Undirected Neural Graphs\n",
    "# Identifies clusters of tightly interconnected neurons using modularity optimization\n",
    "\n",
    "import pandas as pd\n",
    "import igraph as ig\n",
    "import leidenalg as la\n",
    "import numpy as np\n",
    "import ast\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# === USER INPUT ===\n",
    "edge_weights_path = r\"/your/path/to/mean_edge_weights_single_animal.xlsx\"  # <-- CHANGE THIS\n",
    "output_image_path = \"community_detection.png\"  # <-- CHANGE IF NEEDED\n",
    "\n",
    "# === FUNCTION DEFINITION ===\n",
    "def detect_communities_leiden(edge_weights_path, image_path=\"community_detection.png\"):\n",
    "    \"\"\"\n",
    "    Detects neuronal communities using the Leiden algorithm on an undirected graph.\n",
    "\n",
    "    The graph is constructed from mean edge weights between neuron pairs. \n",
    "    The Leiden algorithm partitions the graph to maximize modularity, identifying\n",
    "    clusters of tightly interconnected neurons.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    edge_weights_path : str\n",
    "        Path to Excel file containing:\n",
    "        - 'Neuron Pair': string-formatted tuple (e.g., \"(1, 2)\")\n",
    "        - 'Mean Edge Weight': positive float\n",
    "    \n",
    "    image_path : str, optional\n",
    "        Path to save the community detection visualization. Default is 'community_detection.png'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    partition : leidenalg.VertexPartition\n",
    "        The community partition object.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function assumes the input file contains data from a single animal.\n",
    "    If you have multiple animals in one file, you must preprocess and run separately.\n",
    "\n",
    "    The graph is undirected. Edge weights are used for modularity optimization,\n",
    "    but directionality is ignored.\n",
    "\n",
    "    The Leiden algorithm is chosen over Louvain and other community detection methods\n",
    "    due to its superior performance in detecting well-separated and stable communities.\n",
    "    Compared to Louvain, Leiden:\n",
    "    - Ensures communities are locally well-connected (no disconnected parts)\n",
    "    - Provides faster convergence and better modularity optimization\n",
    "    - Is more robust to resolution parameter changes\n",
    "    These advantages are particularly important for dynamic neural data where \n",
    "    communities may shift across time and subtle changes in modular structure matter.\n",
    "    \"\"\"\n",
    "    # Load data and safely parse tuples\n",
    "    df = pd.read_excel(edge_weights_path)\n",
    "    df['Neuron Pair'] = df['Neuron Pair'].apply(ast.literal_eval)\n",
    "\n",
    "    # Extract source, target, and weight info\n",
    "    sources = df['Neuron Pair'].apply(lambda x: x[0]).tolist()\n",
    "    targets = df['Neuron Pair'].apply(lambda x: x[1]).tolist()\n",
    "    weights = df['Mean Edge Weight'].tolist()\n",
    "\n",
    "    # Build undirected igraph\n",
    "    g = ig.Graph.TupleList(edges=list(zip(sources, targets)), directed=False)\n",
    "    g.es['weight'] = weights\n",
    "\n",
    "    # Apply Leiden algorithm\n",
    "    partition = la.find_partition(g, la.ModularityVertexPartition, weights='weight')\n",
    "\n",
    "    # Visualization\n",
    "    def plot_graph(graph, partition, weights, image_path):\n",
    "        percentiles = np.percentile(weights, np.arange(0, 100, 0.1))\n",
    "        edge_widths = []\n",
    "        edge_colors = []\n",
    "        min_w, max_w = min(weights), max(weights)\n",
    "\n",
    "        for weight in weights:\n",
    "            norm_weight = (weight - min_w) / (max_w - min_w + 1e-10)\n",
    "            edge_widths.append(norm_weight * 20 + 0.3)\n",
    "            if weight > 0:\n",
    "                percentile_rank = next((x[0] for x in enumerate(percentiles) if x[1] >= weight), len(percentiles) - 1) / 1000.0\n",
    "                intensity = percentile_rank * 0.9 + 0.1\n",
    "                edge_colors.append((0, 0, 0, intensity))\n",
    "            else:\n",
    "                edge_colors.append((0, 0, 0, 0))\n",
    "\n",
    "        node_colors = ['red' if sum(graph.es.select(_source=v.index)['weight']) == 0 else 'green' for v in graph.vs]\n",
    "\n",
    "        visual_style = {\n",
    "            \"vertex_size\": 40,\n",
    "            \"vertex_color\": node_colors,\n",
    "            \"edge_color\": edge_colors,\n",
    "            \"edge_width\": edge_widths,\n",
    "            \"vertex_label\": list(range(1, graph.vcount() + 1)),\n",
    "            \"bbox\": (800, 800),\n",
    "            \"margin\": 100,\n",
    "        }\n",
    "\n",
    "        ig.plot(graph, image_path, **visual_style)\n",
    "        return Image(filename=image_path_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec25333c-a49e-490b-b90f-7f552db0c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigenvector Centrality per Neuron per Animal\n",
    "# Measures influence of each neuron based on connections to other high-centrality neurons\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import ast\n",
    "\n",
    "# === USER INPUT ===\n",
    "edge_weights_path = r\"/your/path/to/mean_edge_weights_all_animals.csv\"  # <-- CHANGE THIS\n",
    "output_path = r\"/your/path/to/eigenvector_centrality_results.csv\"        # <-- CHANGE THIS\n",
    "\n",
    "# === FUNCTION DEFINITION ===\n",
    "def compute_eigenvector_centrality(edge_weights_path, output_path=\"eigenvector_centrality_results.csv\"):\n",
    "    \"\"\"\n",
    "    Compute eigenvector centrality for each neuron in an undirected, weighted graph per animal.\n",
    "\n",
    "    Eigenvector centrality measures a neuron's influence based on its connections to other \n",
    "    high-scoring neurons. It is computed per animal using the 'Animal' column.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    edge_weights_path : str\n",
    "        Path to CSV file containing:\n",
    "        - 'Animal': Animal identifier (e.g., \"WT1\", \"ELS2\")\n",
    "        - 'Neuron Pair': stringified tuple (e.g., \"(1, 3)\")\n",
    "        - 'Mean Edge Weight': positive float\n",
    "\n",
    "    output_path : str, optional\n",
    "        Path to save the resulting centrality scores as a CSV file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    eigenvector_df : pandas.DataFrame\n",
    "        DataFrame with columns:\n",
    "        - 'Animal'\n",
    "        - 'Neuron'\n",
    "        - 'Eigenvector Centrality'\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function assumes the input file includes multiple animals. \n",
    "    Graphs are built per animal using undirected edges with weights.\n",
    "    If convergence fails (e.g., due to disconnected components), the result for that animal is skipped.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(edge_weights_path)\n",
    "    data['Mean Edge Weight'] = pd.to_numeric(data['Mean Edge Weight'], errors='coerce')\n",
    "    data['Neuron Pair'] = data['Neuron Pair'].apply(ast.literal_eval)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for animal, group in data.groupby('Animal'):\n",
    "        G = nx.Graph()\n",
    "        for _, row in group.iterrows():\n",
    "            source, target = row['Neuron Pair']\n",
    "            weight = row['Mean Edge Weight']\n",
    "            G.add_edge(source, target, weight=weight)\n",
    "\n",
    "        if G.number_of_edges() == 0:\n",
    "            print(f\"Warning: No edges found for Animal {animal}.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            eigen_centrality = nx.eigenvector_centrality(G, weight='weight', max_iter=1000, tol=1e-06)\n",
    "        except nx.PowerIterationFailedConvergence:\n",
    "            print(f\"Warning: Eigenvector Centrality failed to converge for Animal {animal}.\")\n",
    "            continue\n",
    "\n",
    "        for node, score in eigen_centrality.items():\n",
    "            results.append({\n",
    "                'Animal': animal,\n",
    "                'Neuron': node,\n",
    "                'Eigenvector Centrality': score\n",
    "            })\n",
    "\n",
    "    eigenvector_df = pd.DataFrame(results)\n",
    "    eigenvector_df.to_csv(output_path, index=False)\n",
    "    return eigenvector_df\n",
    "\n",
    "# === RUN FUNCTION ===\n",
    "eigenvector_df = compute_eigenvector_centrality(edge_weights_path, output_path)\n",
    "\n",
    "print(\"Eigenvector Centrality Results:\")\n",
    "print(eigenvector_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b7572-37cd-401b-9d6f-2dbe48d86df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted Global and Local Efficiency per Animal\n",
    "# Uses distance = 1 - weight for functional connectivity interpretation\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "# === USER INPUT ===\n",
    "edge_weights_path = r\"/your/path/to/mean_edge_weights_all_animals.csv\"  # <-- CHANGE THIS\n",
    "output_path = r\"/your/path/to/baseline_efficiency_results_animal_level.csv\"  # <-- CHANGE THIS\n",
    "\n",
    "# === EFFICIENCY FUNCTIONS ===\n",
    "def global_efficiency(graph):\n",
    "    n = len(graph)\n",
    "    if n < 2:\n",
    "        return 0\n",
    "    efficiency_sum = 0\n",
    "    for _, target_lengths in nx.all_pairs_dijkstra_path_length(graph, weight='weight'):\n",
    "        for dist in target_lengths.values():\n",
    "            if dist > 0:\n",
    "                efficiency_sum += 1 / dist\n",
    "    return efficiency_sum / (n * (n - 1))\n",
    "\n",
    "def local_efficiency(graph):\n",
    "    efficiencies = []\n",
    "    for v in graph.nodes:\n",
    "        neighbors = list(graph.neighbors(v))\n",
    "        if len(neighbors) > 1:\n",
    "            subgraph = graph.subgraph(neighbors)\n",
    "            efficiencies.append(global_efficiency(subgraph))\n",
    "    return np.mean(efficiencies) if efficiencies else 0\n",
    "\n",
    "# === MAIN FUNCTION ===\n",
    "def compute_efficiency_metrics(edge_weights_path, output_path=\"efficiency_results.csv\"):\n",
    "    \"\"\"\n",
    "    Compute global and local efficiency for each animal using functional connectivity-based distances.\n",
    "\n",
    "    Global efficiency measures how efficiently information is exchanged across the network.\n",
    "    Local efficiency measures how efficiently information is exchanged within local neighborhoods.\n",
    "    This implementation uses a biologically grounded transformation of functional connectivity \n",
    "    (bounded between 0 and 1) into distance values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    edge_weights_path : str\n",
    "        Path to CSV file with:\n",
    "        - 'Animal': Animal identifier\n",
    "        - 'Neuron Pair': string-formatted tuple, e.g., \"(1, 2)\"\n",
    "        - 'Mean Edge Weight': normalized functional connectivity between neurons (range: 0 to 1)\n",
    "\n",
    "    output_path : str, optional\n",
    "        Path to save the resulting efficiency metrics. Default is 'efficiency_results.csv'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results_df : pandas.DataFrame\n",
    "        DataFrame with columns: 'Animal', 'Global Efficiency', 'Local Efficiency'\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Graphs are undirected and constructed per animal\n",
    "    - Edge weights represent functional connectivity (0 to 1), with higher values \n",
    "      indicating stronger connections\n",
    "    - To convert connectivity to distance for efficiency calculations, we use:\n",
    "          distance = 1 - weight\n",
    "      so that stronger connections result in shorter distances and higher efficiency\n",
    "    - If the graph is disconnected, only the largest connected component is used\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(edge_weights_path)\n",
    "    data['Mean Edge Weight'] = pd.to_numeric(data['Mean Edge Weight'], errors='coerce')\n",
    "    data['Neuron Pair'] = data['Neuron Pair'].apply(ast.literal_eval)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for animal, group in data.groupby('Animal'):\n",
    "        G = nx.Graph()\n",
    "        for _, row in group.iterrows():\n",
    "            source, target = row['Neuron Pair']\n",
    "            weight = row['Mean Edge Weight']\n",
    "            if 0 <= weight <= 1:\n",
    "                distance = 1 - weight\n",
    "                G.add_edge(source, target, weight=distance)\n",
    "\n",
    "        if G.number_of_edges() == 0:\n",
    "            global_eff = 0\n",
    "            local_eff = 0\n",
    "        else:\n",
    "            if not nx.is_connected(G):\n",
    "                largest_component = max(nx.connected_components(G), key=len)\n",
    "                G = G.subgraph(largest_component).copy()\n",
    "\n",
    "            global_eff = global_efficiency(G)\n",
    "            local_eff = local_efficiency(G)\n",
    "\n",
    "        results.append({\n",
    "            'Animal': animal,\n",
    "            'Global Efficiency': global_eff,\n",
    "            'Local Efficiency': local_eff\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(output_path, index=False)\n",
    "    return results_df\n",
    "\n",
    "# === RUN FUNCTION ===\n",
    "results_df = compute_efficiency_metrics(edge_weights_path, output_path)\n",
    "\n",
    "print(\"Efficiency Metrics:\")\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch22)",
   "language": "python",
   "name": "pytorch22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
